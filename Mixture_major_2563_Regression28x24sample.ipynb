{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-correspondence",
   "metadata": {},
   "source": [
    "# DNA and Bone\n",
    "# 2/3/2564 Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-assist",
   "metadata": {},
   "source": [
    "## 10 input && 2 output\n",
    "## 28x24 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#conda install -c anaconda xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "# pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input\n",
    "columns_input = ['Allele_1', 'Allele_2', 'Allele_3', 'Allele_4', 'Allele_5',\n",
    "                  'Height_1', 'Height_2', 'Height_3', 'Height_4', 'Height_5']\n",
    "## Output\n",
    "columns_output = ['Out_1', 'Out_2']\n",
    "\n",
    "print(len(columns_input))\n",
    "print(len(columns_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = []\n",
    "columns_names = columns_input + columns_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns_names[0])\n",
    "print(columns_names[5])\n",
    "print(columns_names[8])\n",
    "print(columns_names[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'new_V2_mix_major_Full.xlsx'\n",
    "path_adress = \"C:\\\\Users\\\\MSI-1016TH\\\\Google Drive\\\\DNA_project_Code\\\\\"\n",
    "dataset_path = path_adress + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet1 = 'Sheet4'\n",
    "cols = 'c:l'\n",
    "df_input = pd.read_excel(dataset_path, sheet_name=sheet1, header=None, skiprows=[0,1], usecols=cols)\n",
    "cols = 'm:n'\n",
    "df_output = pd.read_excel(dataset_path, sheet_name=sheet1, header=None, skiprows=[0,1], usecols=cols)\n",
    "cols = 'c:n'\n",
    "df_all = pd.read_excel(dataset_path, sheet_name=sheet1, header=None, skiprows=[0,1], usecols=cols)\n",
    "\n",
    "#df_input\n",
    "df_all.head()\n",
    "#df_output\n",
    "\n",
    "#df.head()\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.fillna(0) # แทนค่า nan = 0\n",
    "df_all = df_all.replace('X', 1)\n",
    "df_all = df_all.replace('Y', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All\n",
    "\n",
    "major = 28 # sample\n",
    "marker_rows = 24\n",
    "marker_columns = 10+2\n",
    "\n",
    "lst_all = []\n",
    "num_columns = marker_columns # newcolumns\n",
    "lst_all = [0] * (major*marker_rows) # Generate Rows\n",
    "for i in range(len(lst_all)):\n",
    "    lst_all[i] = [0] * num_columns\n",
    "\n",
    "for k in range(0,major):\n",
    "    count = k * marker_rows\n",
    "    lst = []\n",
    "    df_temp = df_all[24*k:(24*k)+24]\n",
    "    array_temp = df_temp.to_numpy()\n",
    "    lst = array_temp.tolist()\n",
    "    del df_temp, array_temp\n",
    "    for i in range(0,marker_rows):\n",
    "        for j in range(0,marker_columns):\n",
    "            #lst_all[count][j] = lst[i][j]\n",
    "            if j < 4 :\n",
    "                lst_all[count][j] = lst[i][j]/100\n",
    "            elif j >= 5 and j < 10:\n",
    "                lst_all[count][j] = lst[i][j]/10000\n",
    "            elif j >= 10 and j < 12:\n",
    "                lst_all[count][j] = lst[i][j]/100\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lst_all))     #rows\n",
    "print(len(lst_all[0]))  #columns\n",
    "print(len(lst_all[10]))  #columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-dallas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_all = pd.DataFrame(lst_all, columns=columns_names)\n",
    "dataset_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all[0:605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_all.copy()\n",
    "train_dataset = dataset.sample(frac=0.9, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns_input)\n",
    "print(columns_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('column_name', 1)\n",
    "train_data = train_dataset.drop(columns=columns_output)\n",
    "train_labels = train_dataset.drop(columns=columns_input)\n",
    "\n",
    "test_data = test_dataset.drop(columns=columns_output)\n",
    "test_labels = test_dataset.drop(columns=columns_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n",
    "#df.head()\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_labels.head()\n",
    "(test_labels*100)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง neural network โดยใข้  Library keras\n",
    "\n",
    "def build_model():\n",
    "    # define the model ระบุโมเดล\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(2048, activation='relu', input_shape=[len(train_data.keys())]),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    \n",
    "    # define optimizer ระบุ optimizer\n",
    "    #optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    \n",
    "    # สร้าง model และระบุ loss function แบบ mean square error\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['mae','mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model() # สร้าง model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_result = model.predict(train_data[:5]) # ทดสอบดูว่า model เราสามารถทำงานได้\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทำการ training โมเดล โดยแบ่งข้อมูลสำหรับ test เป็น 10% จากชุดข้อมูล\n",
    "EPOCHS = 500\n",
    "\n",
    "history = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=EPOCHS, validation_split=0.1, verbose=0,\n",
    "    callbacks=[tfdocs.modeling.EpochDots()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2) #สร้าง 0bject plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ดูผล accuracy ของ training\n",
    "plotter.plot({'Basic':history}, metric = 'mae')\n",
    "plt.ylim([0,10])\n",
    "plt.ylabel('MAE [mpg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ดูผล Mean square error ของ training\n",
    "plotter.plot({'Basic':history}, metric = 'mse')\n",
    "plt.ylim([0,10])\n",
    "plt.ylabel('MSE [mpg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(test_data, test_labels, verbose=2) \n",
    "# ประเมิน โดยการทดสอบกับข้อมูลที่มันไม่เคยเห็น\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} mpg\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ข้อมูล prediction จาก model ที่ train แล้ว \n",
    "test_predictions = model.predict(test_data)\n",
    "#test_predictions = test_predictions.flatten() # flatten ให้เป็น array 1 มิติ\n",
    "test_predictions*100\n",
    "#type(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data Before Compare with Input\n",
    "predictions_data = test_predictions*100\n",
    "array_test_data = (test_data*100).to_numpy()\n",
    "\n",
    "#print(type(array_test_data))\n",
    "#print(type(predictions_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with Input\n",
    "Perd_labels = np.zeros((67, 2))\n",
    "\n",
    "for k in range(0,len(array_test_data)):\n",
    "    for i in range(0,2):\n",
    "        c = np.array([99])\n",
    "        c_new = np.array([0])\n",
    "        for j in range(0,5):\n",
    "            c_new = abs(predictions_data[k, i] - array_test_data[k, j])\n",
    "            #print(c_new)\n",
    "            if c_new < c:\n",
    "                Perd_labels[k, i] = array_test_data[k, j]\n",
    "                c = c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "Perd_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_data = pd.DataFrame({'Pred_Out_1': Perd_labels[:, 0], 'Pred_Out_2': Perd_labels[:, 1]})\n",
    "predictions_data[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_labels*100\n",
    "array_test_labels = (test_labels*100).to_numpy()\n",
    "array_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบกับค่าที่ไม่เคยสอน\n",
    "count_0_out = 0\n",
    "count_1_out = 0\n",
    "count_2_out = 0\n",
    "for k in range(0,67):\n",
    "    for i in range(0,2):\n",
    "        chk_1 = array_test_labels[k, 0] - Perd_labels[k, 0]\n",
    "        chk_2 = array_test_labels[k, 1] - Perd_labels[k, 1]\n",
    "    if chk_1 == 0 and chk_2 == 0:\n",
    "         count_2_out = count_2_out + 1\n",
    "    if chk_1 == 0 or chk_2 == 0:\n",
    "         count_1_out = count_1_out + 1\n",
    "    if not(chk_1 == 0 or chk_2 == 0):\n",
    "         count_0_out = count_0_out + 1\n",
    "\n",
    "print(\"Predictions 2 Out :\", count_2_out)\n",
    "print(\"Predictions 2 Out :\", (count_2_out/67)*100, \"%\")\n",
    "print(\"Predictions 1 Out :\",count_1_out-count_2_out)\n",
    "print(\"Predictions 1 Out :\", ((count_1_out-count_2_out)/67)*100, \"%\")\n",
    "print(\"Predictions 0 Out :\",count_0_out)\n",
    "print(\"Predictions 0 Out :\", (count_0_out/67)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-republican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบกับค่าที่เคยสอน\n",
    "#train_data\n",
    "#train_labels\n",
    "array_train_labels = (train_labels*100).to_numpy()\n",
    "array_train_labels\n",
    "\n",
    "# run ข้อมูล prediction จาก model ที่ train แล้ว \n",
    "train_predictions = model.predict(train_data)\n",
    "#test_predictions = test_predictions.flatten() # flatten ให้เป็น array 1 มิติ\n",
    "#test_predictions*100\n",
    "#type(test_predictions)\n",
    "\n",
    "# Prepare Data Before Compare with Input\n",
    "predictions_data = train_predictions*100\n",
    "array_train_data = (train_data*100).to_numpy()\n",
    "\n",
    "#print(type(array_test_data))\n",
    "#print(type(predictions_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบกับค่าที่เคยสอน\n",
    "# compare with Input\n",
    "Perd_labels = np.zeros((605, 2))\n",
    "\n",
    "for k in range(0,len(array_train_data)):\n",
    "    for i in range(0,2):\n",
    "        c = np.array([99])\n",
    "        c_new = np.array([0])\n",
    "        for j in range(0,5):\n",
    "            c_new = abs(predictions_data[k, i] - array_train_data[k, j])\n",
    "            #print(c_new)\n",
    "            if c_new < c:\n",
    "                Perd_labels[k, i] = array_train_data[k, j]\n",
    "                c = c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบกับค่าที่เคยสอน\n",
    "\n",
    "count_1_out = 0\n",
    "count_2_out = 0\n",
    "for k in range(0,605):\n",
    "    for i in range(0,2):\n",
    "        chk_1 = array_train_labels[k, 0] - Perd_labels[k, 0]\n",
    "        chk_2 = array_train_labels[k, 1] - Perd_labels[k, 1]\n",
    "    if chk_1 == 0 and chk_2 == 0:\n",
    "         count_2_out = count_2_out + 1\n",
    "    if chk_1 == 0 or chk_2 == 0:\n",
    "         count_1_out = count_1_out + 1\n",
    "\n",
    "print(\"Predictions 2 Out :\", count_2_out)\n",
    "print(\"Predictions 2 Out :\", (count_2_out/605)*100, \"%\")\n",
    "print(\"Predictions 1 Out :\",count_1_out)\n",
    "print(\"Predictions 1 Out :\", (count_1_out/605)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2_DNA",
   "language": "python",
   "name": "tfdna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
